# Machine_Learning_Workflows

# HADOOP and Spark Installation
In this section, we have installed HADOOP and Spark

# A basic word count program 
Used MapReduce Algorithm To get the total number of words from a text file. To achieve this, we have used Spark for
distributed data processing.

# Open_Source_Attack_Visualization
In this section, we have considered dataset from https://raw.githubusercontent.com/IQTLabs/software-supply-chain-compromises/master/software_supply_chain_attacks.csv

and categorize attacks initiated from the open source project and other sources by REGEX matching.

Then we have calculated the number of attack initiated from the open source project and other sources. 

Then, we plot the data of the number of attack initiaed from the open source and other sources and show a 
visualization. 